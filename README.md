# tiny-accelerate
A minimal from scratch implementation of ðŸ¤— Accelerate + Nanotron for multiple DL distributed and parallel training approaches

## Data Parallel
1. bucket.py has `Bucket` and `BucketManager` and helps with gradient bucketing.
2. data-parallel-main.py to help run the code
3. Some other files with code for simpler to optimzied approaches. 
